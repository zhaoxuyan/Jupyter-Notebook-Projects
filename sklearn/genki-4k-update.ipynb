{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# genki-4k 数据集 人脸表情检测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义face_cutter：识别人脸并裁剪"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def face_cutter(file,k):\n",
    "    import dlib\n",
    "    import numpy as np\n",
    "    import cv2\n",
    "    # dlib预测器\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor\n",
    "    ('/Users/zhaoxuyan/Desktop/shape_predictor_68_face_landmarks.dat')\n",
    "    # 读取图片路径\n",
    "    img = cv2.imread(file,0)\n",
    "    path_save = '/Users/zhaoxuyan/Desktop/genki-4k-cutted-num/'\n",
    "    \n",
    "    # dlib检测\n",
    "    dets = detector(img, 1)\n",
    "    \n",
    "    try:\n",
    "        if(len(dets) == 1):\n",
    "            for m,d in enumerate(dets):\n",
    "                # 计算矩阵大小\n",
    "                pos_start = tuple([d.left(), d.top()])\n",
    "                pos_end = tuple([d.right(), d.bottom()])\n",
    "\n",
    "                print (k)\n",
    "                # 计算矩形框大小\n",
    "                height = d.bottom() - d.top()\n",
    "                width = d.right() - d.left()\n",
    "\n",
    "                # 根据人脸大小生成空的图像\n",
    "                img_blank = np.zeros((height, width, 3), np.uint8)\n",
    "\n",
    "                for i in range(height):\n",
    "                    for j in range(width):\n",
    "                        img_blank[i][j] = img[d.top() + i][d.left() + j]\n",
    "                \n",
    "                cv2.imwrite(path_save+str(k)+\".jpg\", img_blank)\n",
    "        else:\n",
    "            print (\"未检测到人脸的图片：\",file)\n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os  \n",
    "path_read = \"/Users/zhaoxuyan/Desktop/genki-4k\"  #待读取的文件夹  \n",
    "files=os.listdir(path_read)  \n",
    "files.sort() #对读取的路径进行排序  \n",
    "k=0\n",
    "for file in files: \n",
    "    k=k+1\n",
    "    face_cutter(os.path.join(path_read,file),k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 统一图片尺寸  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image  \n",
    "import os.path  \n",
    "import glob  \n",
    "def convertjpg(jpgfile,outdir,width=128,height=128):  \n",
    "    img=Image.open(jpgfile)  \n",
    "    try:  \n",
    "        new_img=img.resize((width,height),Image.BILINEAR)     \n",
    "        new_img.save(os.path.join(outdir,os.path.basename(jpgfile)))  \n",
    "    except Exception as e:  \n",
    "        print(e)  \n",
    "for jpgfile in glob.glob(\"/Users/zhaoxuyan/Desktop/genki-4k-cutted-num/*.jpg\"):  \n",
    "    convertjpg(jpgfile,\"/Users/zhaoxuyan/Desktop/genki-4k-resize-num\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## HOG特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dlib\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "bin_n = 16*16 # Number of bins\n",
    "def hog(img):\n",
    "    x_pixel,y_pixel=128,128\n",
    "    gx = cv2.Sobel(img, cv2.CV_32F, 1, 0)\n",
    "    gy = cv2.Sobel(img, cv2.CV_32F, 0, 1)\n",
    "    #cartToPolar函数参照 http://www.hahack.com/wiki/opencv-image.html\n",
    "    mag, ang = cv2.cartToPolar(gx, gy)\n",
    "    bins = np.int32(bin_n*ang/(2*np.pi))    # quantizing binvalues in (0...16)\n",
    "    bin_cells = bins[:(int)(x_pixel/2),:(int)(y_pixel/2)], bins[(int)(x_pixel/2):,:(int)(y_pixel/2)], bins[:(int)(x_pixel/2),(int)(y_pixel/2):], bins[(int)(x_pixel/2):,(int)(y_pixel/2):]\n",
    "    mag_cells = mag[:(int)(x_pixel/2),:(int)(y_pixel/2)], mag[(int)(x_pixel/2):,:(int)(y_pixel/2)], mag[:(int)(x_pixel/2),(int)(y_pixel/2):], mag[(int)(x_pixel/2):,(int)(y_pixel/2):]\n",
    "    #bincount()统计出现的次数 参照http://blog.csdn.net/lanchunhui/article/details/50491632\n",
    "    #ravel()参照http://blog.csdn.net/lanchunhui/article/details/50354978\n",
    "    hists = [np.bincount(b.ravel(), m.ravel(), bin_n) for b, m in zip(bin_cells, mag_cells)]\n",
    "    #hstack()返回结果为numpy的数组\n",
    "    hist = np.hstack(hists)     # hist is a 64 bit vector\n",
    "#    print hist.shape\n",
    "#    print type(hist)\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 得到data和target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=[]\n",
    "import os  \n",
    "path=\"/Users/zhaoxuyan/Desktop/genki-4k-resize-num\"  #待读取的文件夹  \n",
    "files=os.listdir(path)  \n",
    "files.sort(key= lambda x:int(x[:-4])) #对读取的路径进行排序  \n",
    "for file in files:  \n",
    "    im = cv2.imread(os.path.join(path,file))\n",
    "    h = hog(im)\n",
    "    X.append(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 经过HOG提取特征后，每一个样本有1024维特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 去掉了识别不出人脸的图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_1 =  [1 for x in range(1,2163)]  \n",
    "y_0 = [0 for x in range(2163,3778)]\n",
    "y = y_1 + y_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# B=[]\n",
    "# for i in range(0,len(X)):\n",
    "#     A=X[i].reshape(1,-1)\n",
    "#     B.append(A[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = X\n",
    "target = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练集验证集拆分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        data, target, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA降维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA done in 0.389s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from time import time\n",
    "n_components = 50 \n",
    "t0 = time()  \n",
    "pca = PCA(n_components=n_components, svd_solver='randomized', #选择一种svd方式  \n",
    "          whiten=True).fit(X_train)    #whiten是一种数据预处理方式，会损失一些数据信息，但可获得更好的预测结果 \n",
    "print(\"PCA done in %0.3fs\" % (time() - t0))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.08274537e+00,  1.41854601e+00, -7.82999631e-01, -1.37905071e+00,\n",
       "       -1.75608564e+00,  2.71394797e-04, -3.62333355e-01, -2.46178849e-01,\n",
       "        2.48364811e-01,  1.53777171e+00,  2.59631454e-01,  6.14545369e-01,\n",
       "       -1.88123757e+00,  5.24016044e-02, -3.62002152e-01,  9.49130403e-01,\n",
       "        2.77186501e-01,  1.23911291e+00,  4.21632076e-02,  1.26671358e+00,\n",
       "       -2.74698786e-01, -2.87840355e-01, -8.73012972e-01, -9.42591945e-01,\n",
       "       -4.57003553e-01, -8.83772121e-01,  1.39381675e+00,  1.42234239e+00,\n",
       "       -4.49552230e-01,  1.75423118e+00,  1.14817822e-01, -6.41790811e-01,\n",
       "       -1.25413955e+00, -3.64756153e-01,  1.42116910e+00, -1.58053261e+00,\n",
       "       -1.51040233e+00,  1.17185833e-01, -6.87361731e-01,  8.20418126e-02,\n",
       "       -9.16429145e-01,  6.79856648e-01,  1.34132195e+00, -3.67830873e-01,\n",
       "        1.29177845e+00,  1.69792237e+00, -1.14477360e-01, -2.05738241e+00,\n",
       "        2.23396318e-01, -1.47224856e-02])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca = pca.transform(X_train)      #得到训练集投影系数  \n",
    "X_test_pca = pca.transform(X_test)        #得到测试集投影系数  \n",
    "X_train_pca[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV done in 530.925s\n",
      "Best estimator found by grid search:\n",
      "SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "best score: 0.742585\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "\n",
    "t0 = time() \n",
    "kfold = KFold(n_splits=2)\n",
    "scoring_fnc = make_scorer(accuracy_score)\n",
    "# param_grid = [{'C': [1e3, 5e3, 1e4, 5e4],  \n",
    "#               'gamma': [0.0001, 0.0005, 0.001]}]\n",
    "param_grid = [{'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "clf = GridSearchCV(SVC(kernel='linear', class_weight='balanced'), param_grid, scoring_fnc, cv=kfold)  \n",
    "# class_weight='balanced'表示调整各类别权重，权重与该类中样本数成反比，  \n",
    "# 防止模型过于拟合某个样本数量过大的类  \n",
    "clf = clf.fit(X_train_pca, y_train)  \n",
    "print(\"GridSearchCV done in %0.3fs\" % (time() - t0))  \n",
    "print(\"Best estimator found by grid search:\")  \n",
    "print(clf.best_estimator_)\n",
    "print('best score: %f'%clf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k折交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.82 (+/- 0.01)\n",
      "交叉验证时间： 194.83248925209045\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import time\n",
    "time_start=time.time()\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=2)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "time_end=time.time()\n",
    "print('交叉验证时间：',time_end-time_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - 2折交叉验证分数：82(+/- 1)%\n",
    "- 交叉验证时间： 194.83248925209045 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def train_and_evaluate(clf, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    time_start=time.time()\n",
    "    print (\"Accuracy on training set:\")\n",
    "    print (clf.score(X_train, y_train)) \n",
    "    time_end=time.time()\n",
    "    print('模型训练时长：',time_end-time_start)\n",
    "    \n",
    "    print (\"Accuracy on testing set:\")\n",
    "    print (clf.score(X_test, y_test))\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    print (\"Classification Report:\")\n",
    "    print (metrics.classification_report(y_test, y_pred))\n",
    "    print (\"Confusion Matrix:\")\n",
    "    print (metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评价(precision  recall  f1-score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set:\n",
      "1.0\n",
      "模型训练时长： 151.17432117462158\n",
      "Accuracy on testing set:\n",
      "0.8317460317460318\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.80      0.81       414\n",
      "          1       0.85      0.85      0.85       531\n",
      "\n",
      "avg / total       0.83      0.83      0.83       945\n",
      "\n",
      "Confusion Matrix:\n",
      "[[332  82]\n",
      " [ 77 454]]\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate(clf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - 模型训练时间：151.17432117462158 s\n",
    "- 训练准确率：100%\n",
    "- 验证准确率：83%\n",
    "- 精确率：83%\n",
    "- 召回率：83%\n",
    "- F1 score：83%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存训练好的模型到本地"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_model.m']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "os.chdir(\"/Users/zhaoxuyan/Desktop/genki-4k-model\")\n",
    "joblib.dump(clf, \"train_model.m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 从本地调回模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "clf = joblib.load(\"/Users/zhaoxuyan/Desktop/genki-4k-model/train_model.m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#提取目录下所有图片,更改尺寸后保存到另一目录  \n",
    "from PIL import Image  \n",
    "import os.path  \n",
    "import glob  \n",
    "def convertjpg(jpgfile,outdir,width=128,height=128):  \n",
    "    img=Image.open(jpgfile)  \n",
    "    try:  \n",
    "        new_img=img.resize((width,height),Image.BILINEAR)     \n",
    "        new_img.save(os.path.join(outdir,os.path.basename(jpgfile)))  \n",
    "    except Exception as e:  \n",
    "        print(e)  \n",
    "for jpgfile in glob.glob(\"/Users/zhaoxuyan/Desktop/pred/*.jpg\"):  \n",
    "    convertjpg(jpgfile,\"/Users/zhaoxuyan/Desktop/pred_resize\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zhaoxuyan/Desktop/pred_resize/no_smile.jpg\n",
      "/Users/zhaoxuyan/Desktop/pred_resize/smile.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "X=[]\n",
    "import os  \n",
    "path=\"/Users/zhaoxuyan/Desktop/pred_resize\"  #待读取的文件夹  \n",
    "files=os.listdir(path)  \n",
    "for file in files:  \n",
    "    print (os.path.join(path,file))\n",
    "    im = cv2.imread(os.path.join(path,file),0)\n",
    "    h = hog(im)\n",
    "    X.append(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 预测2张图片：no_smile和smile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预处理新图片（自拍）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "B=[]\n",
    "for i in range(0,len(X)):\n",
    "    A=X[i].reshape(1,-1)\n",
    "    B.append(A[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.3214328 , 0.3214328 , 0.09034893, ..., 0.22501577, 0.33847058,\n",
       "        0.33847058], dtype=float32),\n",
       " array([0.30610967, 0.23619246, 0.12861842, ..., 0.1217628 , 0.23348024,\n",
       "        0.2570294 ], dtype=float32)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_data = B\n",
    "pred_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 输出预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(pred_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 输出是0和1，即不笑和笑，结果正确"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 摄像头实时预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "\n",
    "def hog(image):\n",
    "    hog = cv2.HOGDescriptor()\n",
    "    h = hog.compute(image)\n",
    "    return h\n",
    "\n",
    "\n",
    "clf = joblib.load(\"/Users/zhaoxuyan/Desktop/genki-4k-model/train_model.m\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import dlib  # 人脸识别的库dlib\n",
    "    import numpy as np  # 数据处理的库numpy\n",
    "    import cv2  # 图像处理的库OpenCv\n",
    "    from PIL import Image\n",
    "\n",
    "    capture = cv2.VideoCapture(0)\n",
    "    size = (int(capture.get(cv2.CAP_PROP_FRAME_WIDTH)), int(capture.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'DIVX')  # 'x264' doesn't work\n",
    "    out = cv2.VideoWriter('/Users/zhaoxuyan/Desktop/result.mp4', fourcc, 20, size, False)\n",
    "\n",
    "    # dlib预测器\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "    # 创建cv2摄像头对象\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # cap.set(propId, value)\n",
    "    # 设置视频参数，propId设置的视频参数，value设置的参数值\n",
    "    cap.set(3, 480)\n",
    "\n",
    "    # 截图screenshoot的计数器\n",
    "    cnt_ss = 0\n",
    "\n",
    "    # 人脸截图的计数器\n",
    "    cnt_p = 0\n",
    "\n",
    "    # 保存\n",
    "    path_save = \"F:/code/python/P_dlib_face_reco/data/get_from_camera/\"\n",
    "\n",
    "    # cap.isOpened（） 返回true/false 检查初始化是否成功\n",
    "    while cap.isOpened():\n",
    "        # cap.read()\n",
    "        # 返回两个值：\n",
    "        #    一个布尔值true/false，用来判断读取视频是否成功/是否到视频末尾\n",
    "        #    图像对象，图像的三维矩阵q\n",
    "        flag, im_rd = cap.read()\n",
    "        # 每帧数据延时1ms，延时为0读取的是静态帧\n",
    "        kk = cv2.waitKey(1)\n",
    "        # 取灰度\n",
    "        img_gray = cv2.cvtColor(im_rd, cv2.COLOR_RGB2GRAY)\n",
    "        # 人脸数rects\n",
    "        rects = detector(img_gray, 0)\n",
    "        # print(len(rects))\n",
    "        # 待会要写的字体\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "        if len(rects) != 0:\n",
    "            # 检测到人脸\n",
    "            # 矩形框\n",
    "            for k, d in enumerate(rects):\n",
    "\n",
    "                # 计算矩形大小\n",
    "                # (x,y), (宽度width, 高度height)\n",
    "                pos_start = tuple([d.left(), d.top()])\n",
    "                pos_end = tuple([d.right(), d.bottom()])\n",
    "\n",
    "                # 计算矩形框大小\n",
    "                height = d.bottom() - d.top()\n",
    "                width = d.right() - d.left()\n",
    "\n",
    "                # 根据人脸大小生成空的图像\n",
    "                cv2.rectangle(im_rd, tuple([d.left(), d.top()]), tuple([d.right(), d.bottom()]), (0, 255, 255), 2)\n",
    "                im_blank = np.zeros((height, width, 3), np.uint8)\n",
    "\n",
    "                for i in range(height):\n",
    "                    for j in range(width):\n",
    "                        im_blank[i][j] = im_rd[d.top() + i][d.left() + j]\n",
    "\n",
    "                # 存储人脸图像文件\n",
    "                cv2.imwrite(\"/Users/zhaoxuyan/Desktop/camera-resize/1.jpg\", im_blank)\n",
    "                img = Image.open(\"/Users/zhaoxuyan/Desktop/camera-resize/1.jpg\")\n",
    "                # resize\n",
    "                new_img = img.resize((128, 128), Image.BILINEAR)\n",
    "                new_img.save(\"/Users/zhaoxuyan/Desktop/camera-resize/1.jpg\")\n",
    "\n",
    "            # 开始调用clf进行实时预测\n",
    "            im = cv2.imread(\"/Users/zhaoxuyan/Desktop/camera-resize/1.jpg\", 0)\n",
    "            # hog特征提取\n",
    "            h = hog(im)\n",
    "            A = h.reshape(1, -1)\n",
    "            B = [A[0]]\n",
    "            pred_data = B\n",
    "            result = clf.predict(pred_data)\n",
    "            e = result.tolist()\n",
    "            print(e)\n",
    "\n",
    "            # im_rd = cv2.putText(im_rd, \"status:\" + str(e[0]), (20, 300), font, 1, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "            im_rd = cv2.putText(im_rd, \"status:\" + str(e[0]), (20, 350), font, 10, (0, 0, 255), 4, cv2.LINE_AA)\n",
    "\n",
    "        else:\n",
    "            # 没有检测到人脸\n",
    "            print(\"未检测到人脸！\")\n",
    "\n",
    "        # 按下q键退出\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        out.write(im_rd)\n",
    "        # 窗口显示\n",
    "        # cv2.namedWindow(\"camera\", 0) # 如果需要摄像头窗口大小可调\n",
    "        cv2.imshow(\"camera\", im_rd)\n",
    "\n",
    "    # 释放摄像头\n",
    "    cap.release()\n",
    "\n",
    "    # 删除建立的窗口\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - 摄像头实时视频见result.mp4\n",
    "- 由于训练集大多数图像都没戴眼镜，测试时戴眼镜准确率很低\n",
    "- 解决方法：取下眼镜后就OK啦~"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 bunnies",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
